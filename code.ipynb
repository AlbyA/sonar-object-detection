{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from os.path import dirname as up\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.metrics import (f1_score, precision_score, recall_score, accuracy_score, \n",
    "                             jaccard_score, hamming_loss, label_ranking_loss, coverage_error)\n",
    "import sklearn.metrics as metr\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from osgeo import gdal\n",
    "from os.path import dirname as up\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = nn.CrossEntropyLoss(ignore_index=-1)(inputs, targets)\n",
    "\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "           \n",
    "        self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Conv2d(in_planes // 16, in_planes, 1, bias=False))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, inputChannel, outputChannel, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inputChannel, outputChannel, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(outputChannel)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(outputChannel, outputChannel)\n",
    "        self.bn2 = nn.BatchNorm2d(outputChannel)\n",
    "        self.downsample = downsample\n",
    "        self.ca = ChannelAttention(outputChannel)\n",
    "        self.sa = SpatialAttention()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        caOutput = self.ca(out)\n",
    "        out = caOutput * out\n",
    "        saOutput = self.sa(out)\n",
    "        out = saOutput * out\n",
    "        return out, saOutput\n",
    "\n",
    "\n",
    "class DownSampleWithAttention(nn.Module):\n",
    "    def __init__(self, inputChannel, outputChannel):\n",
    "        super().__init__()\n",
    "        self.convolution = nn.Sequential(\n",
    "            nn.Conv2d(inputChannel, outputChannel, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(outputChannel),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(outputChannel, outputChannel, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(outputChannel),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.AvgPool2d(2)\n",
    "        )\n",
    "        self.ca = ChannelAttention(outputChannel)\n",
    "        self.sa = SpatialAttention()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.convolution(x)\n",
    "        caOutput = self.ca(x)\n",
    "        x = caOutput * x\n",
    "        saOutput = self.sa(x)\n",
    "        x = saOutput * x\n",
    "        return x, saOutput\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpSampleWithAttention(nn.Module):\n",
    "    def __init__(self, inputChannel, outputChannel):\n",
    "        super().__init__()\n",
    "        self.convolution = nn.Sequential(\n",
    "            nn.Conv2d(inputChannel, outputChannel, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(outputChannel),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(outputChannel, outputChannel, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(outputChannel),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.ca = ChannelAttention(outputChannel)\n",
    "        self.sa = SpatialAttention()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.upsample(x)\n",
    "        x = self.convolution(x)\n",
    "        caOutput = self.ca(x)\n",
    "        x = caOutput * x\n",
    "        saOutput = self.sa(x)\n",
    "        x = saOutput * x\n",
    "        return x, saOutput\n",
    "    \n",
    "class ResidualAttentionUNet(nn.Module):\n",
    "  def __init__(self, inputChannel, outputChannel):\n",
    "    super().__init__()\n",
    "    self.downsample1 = DownSampleWithAttention(inputChannel, 32)\n",
    "    self.downsample2 = DownSampleWithAttention(32, 64)\n",
    "    self.downsample3 = DownSampleWithAttention(64, 128)\n",
    "    self.downsample4 = DownSampleWithAttention(128, 256)\n",
    "    self.downsample5 = DownSampleWithAttention(256, 512)\n",
    "\n",
    "    self.residualBlock1 = ResidualBlock(512, 512)\n",
    "    self.residualBlock2 = ResidualBlock(512, 512)\n",
    "    self.residualBlock3 = ResidualBlock(512, 512)\n",
    "\n",
    "    self.upsample1 = UpSampleWithAttention(512, 256)\n",
    "    self.upsample2 = UpSampleWithAttention(512, 128)\n",
    "    self.upsample3 = UpSampleWithAttention(256, 64)\n",
    "    self.upsample4 = UpSampleWithAttention(128, 32)\n",
    "    self.upsample5 = UpSampleWithAttention(64, 32)\n",
    "    self.classification = nn.Sequential(\n",
    "            nn.Conv2d(32, outputChannel, kernel_size=1),\n",
    "        )\n",
    "\n",
    "  def forward(self, x):\n",
    "    scale128, sa128down = self.downsample1(x)\n",
    "    scale64, sa64down = self.downsample2(scale128)\n",
    "    scale32, sa32down = self.downsample3(scale64)\n",
    "    scale16, sa64down = self.downsample4(scale32)\n",
    "    scale8, sa8down = self.downsample5(scale16)\n",
    "    scale8, sa8down = self.residualBlock1(scale8)\n",
    "    scale8, sa8down = self.residualBlock2(scale8)\n",
    "    scale8, sa8down = self.residualBlock3(scale8)\n",
    "    upscale16, sa16up = self.upsample1(scale8)\n",
    "    upscale16 = torch.cat([upscale16, scale16], dim=1)\n",
    "    upscale32, sa32up = self.upsample2(upscale16)\n",
    "    upscale32 = torch.cat([upscale32, scale32], dim=1)\n",
    "    upscale64, sa64up = self.upsample3(upscale32)\n",
    "    upscale64 = torch.cat([upscale64, scale64], dim=1)\n",
    "    upscale128, sa128up = self.upsample4(upscale64)\n",
    "    upscale128 = torch.cat([upscale128, scale128], dim=1)\n",
    "    upscale256, sa256up = self.upsample5(upscale128)\n",
    "    finaloutput = self.classification(upscale256)\n",
    "    return finaloutput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluation(y_predicted, y_true):\n",
    "\n",
    "    micro_prec = precision_score(y_true, y_predicted, average='micro')\n",
    "    macro_prec = precision_score(y_true, y_predicted, average='macro')\n",
    "    weight_prec = precision_score(y_true, y_predicted, average='weighted')\n",
    "    \n",
    "    micro_rec = recall_score(y_true, y_predicted, average='micro')\n",
    "    macro_rec = recall_score(y_true, y_predicted, average='macro')\n",
    "    weight_rec = recall_score(y_true, y_predicted, average='weighted')\n",
    "        \n",
    "    macro_f1 = f1_score(y_true, y_predicted, average=\"macro\")\n",
    "    micro_f1 = f1_score(y_true, y_predicted, average=\"micro\")\n",
    "    weight_f1 = f1_score(y_true, y_predicted, average=\"weighted\")\n",
    "        \n",
    "    subset_acc = accuracy_score(y_true, y_predicted)\n",
    "    \n",
    "    iou_acc = jaccard_score(y_true, y_predicted, average='macro')\n",
    "\n",
    "    info = {\n",
    "            \"macroPrec\" : macro_prec,\n",
    "            \"microPrec\" : micro_prec,\n",
    "            \"weightPrec\" : weight_prec,\n",
    "            \"macroRec\" : macro_rec,\n",
    "            \"microRec\" : micro_rec,\n",
    "            \"weightRec\" : weight_rec,\n",
    "            \"macroF1\" : macro_f1,\n",
    "            \"microF1\" : micro_f1,\n",
    "            \"weightF1\" : weight_f1,\n",
    "            \"subsetAcc\" : subset_acc,\n",
    "            \"IoU\": iou_acc\n",
    "            }\n",
    "    \n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y_gt, y_pred, labels):\n",
    "    cm      = metr.confusion_matrix  (y_gt, y_pred)\n",
    "    f1_macro= metr.f1_score          (y_gt, y_pred, average='macro')\n",
    "    mPA      = metr.recall_score      (y_gt, y_pred, average='macro')\n",
    "    OA      = metr.accuracy_score    (y_gt, y_pred)\n",
    "    UA      = metr.precision_score   (y_gt, y_pred, average=None)\n",
    "    PA      = metr.recall_score      (y_gt, y_pred, average=None)\n",
    "    f1      = metr.f1_score          (y_gt, y_pred, average=None)\n",
    "    IoC     = metr.jaccard_score     (y_gt, y_pred, average=None)\n",
    "    mIoC     = metr.jaccard_score    (y_gt, y_pred, average='macro')\n",
    "    sz1, sz2 = cm.shape\n",
    "    cm_with_stats             = np.zeros((sz1+4,sz2+2))\n",
    "    cm_with_stats[0:-4, 0:-2] = cm\n",
    "    cm_with_stats[-3  , 0:-2] = np.round(IoC,2)\n",
    "    cm_with_stats[-2  , 0:-2] = np.round(UA,2)\n",
    "    cm_with_stats[-1  , 0:-2] = np.round(f1,2)\n",
    "    cm_with_stats[0:-4,   -1] = np.round(PA,2)\n",
    "    \n",
    "    cm_with_stats[-4  , 0:-2] = np.sum(cm, axis=0) \n",
    "    cm_with_stats[0:-4,   -2] = np.sum(cm, axis=1)\n",
    "    cm_list = cm_with_stats.tolist()\n",
    "    first_row = []\n",
    "    first_row.extend (labels)\n",
    "    first_row.append ('Sum')\n",
    "    first_row.append ('Recall')\n",
    "    first_col = []\n",
    "    first_col.extend(labels)\n",
    "    first_col.append ('Sum')\n",
    "    first_col.append ('IoU')\n",
    "    first_col.append ('Precision')\n",
    "    first_col.append ('F1-score')\n",
    "    idx = 0\n",
    "    for sublist in cm_list:\n",
    "        if   idx == sz1:\n",
    "            sublist[-2]  = 'mPA:'\n",
    "            sublist[-1]  = round(mPA,2)\n",
    "            cm_list[idx] = sublist\n",
    "        elif   idx == sz1+1:\n",
    "            sublist[-2]  = 'mIoU:'\n",
    "            sublist[-1]  = round(mIoC,2)\n",
    "            cm_list[idx] = sublist\n",
    "            \n",
    "        elif idx == sz1+2:\n",
    "            sublist[-2]  = 'OA:'\n",
    "            sublist[-1]  = round(OA,2)\n",
    "            cm_list[idx] = sublist\n",
    "            \n",
    "        elif idx == sz1+3:\n",
    "            cm_list[idx] = sublist\n",
    "            sublist[-2]  = 'F1-macro:'\n",
    "            sublist[-1]  = round(f1_macro,2)    \n",
    "        idx +=1\n",
    "    df = pd.DataFrame(np.array(cm_list))\n",
    "    df.columns = first_row\n",
    "    df.index = first_col\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_distr = torch.Tensor([0.00452, 0.00203, 0.00254, 0.00168, 0.00766, 0.15206, 0.20232,\n",
    "0.35941, 0.00109, 0.20218, 0.03226, 0.00693, 0.01322, 0.01158, 0.00052])\n",
    "\n",
    "bands_mean = np.array([0.05197577, 0.04783991, 0.04056812, 0.03163572, 0.02972606, 0.03457443,\n",
    "0.03875053, 0.03436435, 0.0392113,  0.02358126, 0.01588816]).astype('float32')\n",
    "\n",
    "bands_std = np.array([0.04725893, 0.04743808, 0.04699043, 0.04967381, 0.04946782, 0.06458357,\n",
    "0.07594915, 0.07120246, 0.08251058, 0.05111466, 0.03524419]).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'data'\n",
    "\n",
    "class GenDEBRIS(Dataset): \n",
    "    def __init__(self, mode = 'train', transform=None, standardization=None, path = dataset_path, agg_to_water= True):\n",
    "        \n",
    "        if mode=='train':\n",
    "            self.ROIs = np.genfromtxt(os.path.join(path, 'splits', 'train_X.txt'),dtype='str')\n",
    "                \n",
    "        elif mode=='test':\n",
    "            self.ROIs = np.genfromtxt(os.path.join(path, 'splits', 'test_X.txt'),dtype='str')\n",
    "                \n",
    "        elif mode=='val':\n",
    "            self.ROIs = np.genfromtxt(os.path.join(path, 'splits', 'val_X.txt'),dtype='str')\n",
    "            \n",
    "        else:\n",
    "            raise\n",
    "            \n",
    "        self.X = []           \n",
    "        self.y = []           \n",
    "            \n",
    "        for roi in tqdm(self.ROIs, desc = 'Load '+mode+' set to memory'):\n",
    "            roi_folder = '_'.join(['S2'] + roi.split('_')[:-1])               \n",
    "            roi_name = '_'.join(['S2'] + roi.split('_'))                      \n",
    "            roi_file = os.path.join(path, 'patches', roi_folder,roi_name + '.tif')       \n",
    "            roi_file_cl = os.path.join(path, 'patches', roi_folder,roi_name + '_cl.tif') \n",
    "            \n",
    "            \n",
    "            ds = gdal.Open(roi_file_cl)\n",
    "            temp = np.copy(ds.ReadAsArray().astype(np.int64))\n",
    "            \n",
    "            \n",
    "            if agg_to_water:\n",
    "                temp[temp==15]=7          \n",
    "                temp[temp==14]=7          \n",
    "                temp[temp==13]=7          \n",
    "                temp[temp==12]=7          \n",
    "            \n",
    "            \n",
    "            temp = np.copy(temp - 1)\n",
    "            ds=None                   \n",
    "            \n",
    "            self.y.append(temp)\n",
    "            \n",
    "            \n",
    "            ds = gdal.Open(roi_file)\n",
    "            temp = np.copy(ds.ReadAsArray())\n",
    "            ds=None\n",
    "            self.X.append(temp)          \n",
    "\n",
    "        self.impute_nan = np.tile(bands_mean, (temp.shape[1],temp.shape[2],1))\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.standardization = standardization\n",
    "        self.length = len(self.y)\n",
    "        self.path = path\n",
    "        self.agg_to_water = agg_to_water\n",
    "        \n",
    "    def __len__(self):\n",
    "\n",
    "        return self.length\n",
    "    \n",
    "    def getnames(self):\n",
    "        return self.ROIs\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        img = self.X[index]\n",
    "        target = self.y[index]\n",
    "\n",
    "        img = np.moveaxis(img, [0, 1, 2], [2, 0, 1]).astype('float32')       \n",
    "        \n",
    "        nan_mask = np.isnan(img)\n",
    "        img[nan_mask] = self.impute_nan[nan_mask]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            target = target[:,:,np.newaxis]\n",
    "            stack = np.concatenate([img, target], axis=-1).astype('float32') \n",
    "        \n",
    "            stack = self.transform(stack)\n",
    "\n",
    "            img = stack[:-1,:,:]\n",
    "            target = stack[-1,:,:].long()                                    \n",
    "        \n",
    "        if self.standardization is not None:\n",
    "            img = self.standardization(img)\n",
    "            \n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomRotationTransform:\n",
    "    def __init__(self, angles):\n",
    "        self.angles = angles\n",
    "\n",
    "    def __call__(self, x):\n",
    "        angle = random.choice(self.angles)\n",
    "        return F.rotate(x, angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_weights(class_distribution, c = 1.02):\n",
    "    return 1/torch.log(c + class_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Marine Debris','Dense Sargassum','Sparse Sargassum',\n",
    "          'Natural Organic Material','Ship','Clouds','Marine Water','Sediment-Laden Water',\n",
    "          'Foam','Turbid Water','Shallow Water','Waves','Cloud Shadows','Wakes',\n",
    "          'Mixed Water']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSizeTrain = 8  \n",
    "batchSizeTest = 4  \n",
    "trainOnGPU = True  \n",
    "totalEpochs = 35  \n",
    "logPath = \"final_logs\"  \n",
    "initialLR = 1e-3  \n",
    "decayLR = 0  \n",
    "schedulerLR = \"ms\"  \n",
    "trainOnMac = False  \n",
    "useFocalLoss = False  \n",
    "modelName = \"resattunet\"  \n",
    "bestValidationAccuracy = 0.0\n",
    "\n",
    "logPath = \"./\"+logPath\n",
    "os.makedirs(logPath)\n",
    "writer = SummaryWriter(logPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalEpochs = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seedAll(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def seedWorker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load train set to memory:   0%|          | 0/694 [00:00<?, ?it/s]c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\osgeo\\gdal.py:312: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n",
      "Load train set to memory: 100%|██████████| 694/694 [00:08<00:00, 77.13it/s] \n",
      "Load val set to memory: 100%|██████████| 328/328 [00:04<00:00, 70.19it/s] \n"
     ]
    }
   ],
   "source": [
    "seedAll(0)\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)\n",
    "agg_to_water = True\n",
    "\n",
    "transformTrain = transforms.Compose([transforms.ToTensor(),\n",
    "                                    RandomRotationTransform([-90, 0, 90, 180]),\n",
    "                                    transforms.RandomHorizontalFlip()])\n",
    "    \n",
    "transformTest = transforms.Compose([transforms.ToTensor()])\n",
    "    \n",
    "standardization = transforms.Normalize(bands_mean, bands_std)\n",
    "\n",
    "datasetTrain = GenDEBRIS('train', transform=transformTrain, standardization = standardization, agg_to_water = agg_to_water)\n",
    "datasetTest = GenDEBRIS('val', transform=transformTest, standardization = standardization, agg_to_water = agg_to_water)\n",
    "        \n",
    "trainLoader = DataLoader(datasetTrain, \n",
    "                        batch_size = batchSizeTrain, \n",
    "                        shuffle = True,\n",
    "                        worker_init_fn=seedWorker,\n",
    "                        generator=g)\n",
    "        \n",
    "testLoader = DataLoader(datasetTest, \n",
    "                        batch_size = batchSizeTest, \n",
    "                        shuffle = False,\n",
    "                        worker_init_fn=seedWorker,\n",
    "                        generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if trainOnMac else (\"cuda\" if trainOnGPU else \"cpu\"))\n",
    "model = {\"resattunet\": ResidualAttentionUNet(11, 11)}.get(modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResidualAttentionUNet(\n",
       "  (downsample1): DownSampleWithAttention(\n",
       "    (convolution): Sequential(\n",
       "      (0): Conv2d(11, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.2)\n",
       "      (6): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (ca): ChannelAttention(\n",
       "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "      (fc): Sequential(\n",
       "        (0): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(2, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (sa): SpatialAttention(\n",
       "      (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (downsample2): DownSampleWithAttention(\n",
       "    (convolution): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.2)\n",
       "      (6): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (ca): ChannelAttention(\n",
       "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "      (fc): Sequential(\n",
       "        (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (sa): SpatialAttention(\n",
       "      (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (downsample3): DownSampleWithAttention(\n",
       "    (convolution): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.2)\n",
       "      (6): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (ca): ChannelAttention(\n",
       "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "      (fc): Sequential(\n",
       "        (0): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (sa): SpatialAttention(\n",
       "      (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (downsample4): DownSampleWithAttention(\n",
       "    (convolution): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.2)\n",
       "      (6): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (ca): ChannelAttention(\n",
       "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "      (fc): Sequential(\n",
       "        (0): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (sa): SpatialAttention(\n",
       "      (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (downsample5): DownSampleWithAttention(\n",
       "    (convolution): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.2)\n",
       "      (6): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (ca): ChannelAttention(\n",
       "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "      (fc): Sequential(\n",
       "        (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (sa): SpatialAttention(\n",
       "      (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (residualBlock1): ResidualBlock(\n",
       "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (ca): ChannelAttention(\n",
       "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "      (fc): Sequential(\n",
       "        (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (sa): SpatialAttention(\n",
       "      (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (residualBlock2): ResidualBlock(\n",
       "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (ca): ChannelAttention(\n",
       "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "      (fc): Sequential(\n",
       "        (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (sa): SpatialAttention(\n",
       "      (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (residualBlock3): ResidualBlock(\n",
       "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (ca): ChannelAttention(\n",
       "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "      (fc): Sequential(\n",
       "        (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (sa): SpatialAttention(\n",
       "      (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (upsample1): UpSampleWithAttention(\n",
       "    (convolution): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (upsample): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (ca): ChannelAttention(\n",
       "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "      (fc): Sequential(\n",
       "        (0): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (sa): SpatialAttention(\n",
       "      (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (upsample2): UpSampleWithAttention(\n",
       "    (convolution): Sequential(\n",
       "      (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (upsample): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (ca): ChannelAttention(\n",
       "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "      (fc): Sequential(\n",
       "        (0): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (sa): SpatialAttention(\n",
       "      (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (upsample3): UpSampleWithAttention(\n",
       "    (convolution): Sequential(\n",
       "      (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (upsample): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (ca): ChannelAttention(\n",
       "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "      (fc): Sequential(\n",
       "        (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (sa): SpatialAttention(\n",
       "      (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (upsample4): UpSampleWithAttention(\n",
       "    (convolution): Sequential(\n",
       "      (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (upsample): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (ca): ChannelAttention(\n",
       "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "      (fc): Sequential(\n",
       "        (0): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(2, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (sa): SpatialAttention(\n",
       "      (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (upsample5): UpSampleWithAttention(\n",
       "    (convolution): Sequential(\n",
       "      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (upsample): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (ca): ChannelAttention(\n",
       "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "      (fc): Sequential(\n",
       "        (0): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(2, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (sa): SpatialAttention(\n",
       "      (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (classification): Sequential(\n",
       "    (0): Conv2d(32, 11, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if model is None:\n",
    "    print(\"Enter correct choice of architecture\")\n",
    "    sys.exit()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if agg_to_water:\n",
    "    agg_distr = sum(class_distr[-4:])\n",
    "    class_distr[6] += agg_distr\n",
    "    class_distr = class_distr[:-4]\n",
    "\n",
    "if useFocalLoss:\n",
    "    criterion = FocalLoss()\n",
    "else:\n",
    "    weight = gen_weights(class_distr, c = 1.03)\n",
    "    criterion = torch.nn.CrossEntropyLoss(ignore_index=-1, reduction= 'mean', weight=weight.to(device))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=initialLR, weight_decay=decayLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=initialLR, weight_decay=decayLR)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True) if schedulerLR == \"rop\" else torch.optim.lr_scheduler.MultiStepLR(optimizer, [40, 80, 120, 160], gamma=0.5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:32<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 1\n",
      "Validating model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Macro Precision 0.3909890450192064\n",
      "Test Macro Recall 0.3909890450192064\n",
      "Test Macro F1 0.2906184205683941\n",
      "Test Macro IoU 0.2383595678735855\n",
      "Training for epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:31<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 2\n",
      "Validating model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Macro Precision 0.3233052653090508\n",
      "Test Macro Recall 0.3233052653090508\n",
      "Test Macro F1 0.27673767536962346\n",
      "Test Macro IoU 0.22065785911065\n",
      "Training for epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:31<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 3\n",
      "Validating model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Macro Precision 0.47101601153917216\n",
      "Test Macro Recall 0.47101601153917216\n",
      "Test Macro F1 0.4604655739360463\n",
      "Test Macro IoU 0.40322974940707373\n",
      "Training for epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:31<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 4\n",
      "Validating model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Macro Precision 0.48020486443078253\n",
      "Test Macro Recall 0.48020486443078253\n",
      "Test Macro F1 0.3613331930345986\n",
      "Test Macro IoU 0.29432521356176494\n",
      "Training for epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:32<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 5\n",
      "Validating model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Macro Precision 0.635281007783222\n",
      "Test Macro Recall 0.635281007783222\n",
      "Test Macro F1 0.5605638680666796\n",
      "Test Macro IoU 0.48675304506326894\n",
      "Training for epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:32<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 6\n",
      "Validating model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Macro Precision 0.5267152892257208\n",
      "Test Macro Recall 0.5267152892257208\n",
      "Test Macro F1 0.4861339839370279\n",
      "Test Macro IoU 0.41193489629547336\n",
      "Training for epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:32<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 7\n",
      "Validating model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Macro Precision 0.619858805852311\n",
      "Test Macro Recall 0.619858805852311\n",
      "Test Macro F1 0.5371349198640686\n",
      "Test Macro IoU 0.44498871696928416\n",
      "Training for epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:33<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 8\n",
      "Validating model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Macro Precision 0.636520213813612\n",
      "Test Macro Recall 0.636520213813612\n",
      "Test Macro F1 0.44000608297844157\n",
      "Test Macro IoU 0.34979000795453385\n",
      "Training for epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:33<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 9\n",
      "Validating model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Macro Precision 0.7205066147160516\n",
      "Test Macro Recall 0.7205066147160516\n",
      "Test Macro F1 0.5596717232786663\n",
      "Test Macro IoU 0.4879708619903832\n",
      "Training for epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:32<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 10\n",
      "Validating model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Macro Precision 0.6677523661185996\n",
      "Test Macro Recall 0.6677523661185996\n",
      "Test Macro F1 0.5758285294416869\n",
      "Test Macro IoU 0.49368041041639815\n",
      "Training for epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:33<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 11\n",
      "Validating model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Macro Precision 0.5252922753266177\n",
      "Test Macro Recall 0.5252922753266177\n",
      "Test Macro F1 0.4377045672795324\n",
      "Test Macro IoU 0.3796962083928379\n",
      "Training for epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:33<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 12\n",
      "Validating model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Macro Precision 0.6901209648292569\n",
      "Test Macro Recall 0.6901209648292569\n",
      "Test Macro F1 0.5838597334371304\n",
      "Test Macro IoU 0.4998828950943855\n",
      "Training for epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:33<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 13\n",
      "Validating model\n",
      "Test Macro Precision 0.6655072051920948\n",
      "Test Macro Recall 0.6655072051920948\n",
      "Test Macro F1 0.6050070886361386\n",
      "Test Macro IoU 0.511675808049833\n",
      "Training for epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:33<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 14\n",
      "Validating model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Macro Precision 0.5860632789032484\n",
      "Test Macro Recall 0.5860632789032484\n",
      "Test Macro F1 0.5586589108771962\n",
      "Test Macro IoU 0.469228406648757\n",
      "Training for epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:33<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 15\n",
      "Validating model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Macro Precision 0.6754423324249426\n",
      "Test Macro Recall 0.6754423324249426\n",
      "Test Macro F1 0.569838604793055\n",
      "Test Macro IoU 0.486729181934335\n",
      "Training for epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:32<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 16\n",
      "Validating model\n",
      "Test Macro Precision 0.7446858455125164\n",
      "Test Macro Recall 0.7446858455125164\n",
      "Test Macro F1 0.6470607938042913\n",
      "Test Macro IoU 0.5438856475280782\n",
      "Training for epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:33<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 17\n",
      "Validating model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Macro Precision 0.6675957808098766\n",
      "Test Macro Recall 0.6675957808098766\n",
      "Test Macro F1 0.5377182658913987\n",
      "Test Macro IoU 0.4436888758325782\n",
      "Training for epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:32<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 18\n",
      "Validating model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Macro Precision 0.6581776138957884\n",
      "Test Macro Recall 0.6581776138957884\n",
      "Test Macro F1 0.49361092777728716\n",
      "Test Macro IoU 0.39445111265696203\n",
      "Training for epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:33<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 19\n",
      "Validating model\n",
      "Test Macro Precision 0.7252196660501063\n",
      "Test Macro Recall 0.7252196660501063\n",
      "Test Macro F1 0.6701370218727218\n",
      "Test Macro IoU 0.5746980245981194\n",
      "Training for epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:32<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 20\n",
      "Validating model\n",
      "Test Macro Precision 0.7116341389434687\n",
      "Test Macro Recall 0.7116341389434687\n",
      "Test Macro F1 0.6357012565250698\n",
      "Test Macro IoU 0.5530616657483445\n",
      "Training for epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:31<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 21\n",
      "Validating model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Macro Precision 0.5505746501918543\n",
      "Test Macro Recall 0.5505746501918543\n",
      "Test Macro F1 0.5490328271927463\n",
      "Test Macro IoU 0.4665567838548753\n",
      "Training for epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:31<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 22\n",
      "Validating model\n",
      "Test Macro Precision 0.6716985476262237\n",
      "Test Macro Recall 0.6716985476262237\n",
      "Test Macro F1 0.5437507042293259\n",
      "Test Macro IoU 0.4635203904049753\n",
      "Training for epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:31<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 23\n",
      "Validating model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Macro Precision 0.6409246230410006\n",
      "Test Macro Recall 0.6409246230410006\n",
      "Test Macro F1 0.5247402578804748\n",
      "Test Macro IoU 0.43880791724689966\n",
      "Training for epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:31<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 24\n",
      "Validating model\n",
      "Test Macro Precision 0.7182379519630312\n",
      "Test Macro Recall 0.7182379519630312\n",
      "Test Macro F1 0.6534986581644794\n",
      "Test Macro IoU 0.5551249667102776\n",
      "Training for epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:31<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 25\n",
      "Validating model\n",
      "Test Macro Precision 0.7173974893662355\n",
      "Test Macro Recall 0.7173974893662355\n",
      "Test Macro F1 0.6528122743753735\n",
      "Test Macro IoU 0.5571624678969932\n",
      "Training for epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:31<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 26\n",
      "Validating model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Macro Precision 0.6689556402692417\n",
      "Test Macro Recall 0.6689556402692417\n",
      "Test Macro F1 0.6134288211837765\n",
      "Test Macro IoU 0.5029994116627359\n",
      "Training for epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:31<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 27\n",
      "Validating model\n",
      "Test Macro Precision 0.7331720731435966\n",
      "Test Macro Recall 0.7331720731435966\n",
      "Test Macro F1 0.7156143622118768\n",
      "Test Macro IoU 0.6174746936486849\n",
      "Training for epoch: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:31<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 28\n",
      "Validating model\n",
      "Test Macro Precision 0.7307339978163369\n",
      "Test Macro Recall 0.7307339978163369\n",
      "Test Macro F1 0.7111874833139264\n",
      "Test Macro IoU 0.6088162132605826\n",
      "Training for epoch: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:32<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 29\n",
      "Validating model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Macro Precision 0.6378308121561527\n",
      "Test Macro Recall 0.6378308121561527\n",
      "Test Macro F1 0.5966004074326242\n",
      "Test Macro IoU 0.5083192219938941\n",
      "Training for epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:31<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 30\n",
      "Validating model\n",
      "Test Macro Precision 0.7390059147104395\n",
      "Test Macro Recall 0.7390059147104395\n",
      "Test Macro F1 0.6149783199873053\n",
      "Test Macro IoU 0.5102113318715673\n",
      "Training for epoch: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:31<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 31\n",
      "Validating model\n",
      "Test Macro Precision 0.7049509907250608\n",
      "Test Macro Recall 0.7049509907250608\n",
      "Test Macro F1 0.601234487797346\n",
      "Test Macro IoU 0.49644430930226696\n",
      "Training for epoch: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:34<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 32\n",
      "Validating model\n",
      "Test Macro Precision 0.772668101288711\n",
      "Test Macro Recall 0.772668101288711\n",
      "Test Macro F1 0.6413456372375986\n",
      "Test Macro IoU 0.5353670200134443\n",
      "Training for epoch: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:36<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 33\n",
      "Validating model\n",
      "Test Macro Precision 0.7954756978130518\n",
      "Test Macro Recall 0.7954756978130518\n",
      "Test Macro F1 0.7057256854392887\n",
      "Test Macro IoU 0.6022490403373897\n",
      "Training for epoch: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:36<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 34\n",
      "Validating model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\UZAIR KABEER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Macro Precision 0.7636761532686068\n",
      "Test Macro Recall 0.7636761532686068\n",
      "Test Macro F1 0.744570676303196\n",
      "Test Macro IoU 0.6468721352934909\n",
      "Training for epoch: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:33<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 35\n",
      "Validating model\n",
      "Test Macro Precision 0.6949188971018664\n",
      "Test Macro Recall 0.6949188971018664\n",
      "Test Macro F1 0.6035286959097991\n",
      "Test Macro IoU 0.5122648042228034\n"
     ]
    }
   ],
   "source": [
    "bestMacroF1 = 0.0\n",
    "bestMicroF1 = 0.0\n",
    "bestWeightF1 = 0.0\n",
    "\n",
    "i = 0\n",
    "for epoch in range(1, totalEpochs+1):\n",
    "    trainingBatches = 0\n",
    "    model.train()\n",
    "    print(\"Training for epoch:\",epoch)\n",
    "    for (image, target) in tqdm(trainLoader):\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(image)\n",
    "        loss = criterion(logits, target)\n",
    "        loss.backward()\n",
    "        trainingBatches+=target.shape[0]\n",
    "        writer.add_scalar('Training Loss', loss, i)\n",
    "        i = i + 1\n",
    "        optimizer.step()\n",
    "    print(\"Completed epoch:\",epoch)\n",
    "    print(\"Validating model\")\n",
    "    model.eval()\n",
    "    testBatches = 0\n",
    "    yTrue = []\n",
    "    yPredicted = []\n",
    "    testLossF = []\n",
    "    with torch.no_grad():\n",
    "        for (image, target) in testLoader:\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "            logits = model(image)\n",
    "            loss = criterion(logits, target)\n",
    "            logits = torch.movedim(logits, (0,1,2,3), (0,3,1,2))\n",
    "            logits = logits.reshape((-1,11))\n",
    "            target = target.reshape(-1)\n",
    "            mask = target != -1\n",
    "            logits = logits[mask]\n",
    "            target = target[mask]\n",
    "            probs = torch.nn.functional.softmax(logits, dim=1).cpu().numpy()\n",
    "            target = target.cpu().numpy()\n",
    "            testBatches += target.shape[0]\n",
    "            testLossF.append((loss.data*target.shape[0]).tolist())\n",
    "            yPredicted += probs.argmax(1).tolist()\n",
    "            yTrue += target.tolist()\n",
    "        writer.add_scalar('Testing Loss', sum(testLossF)/testBatches, epoch)\n",
    "        yPredicted = np.asarray(yPredicted)\n",
    "        yTrue = np.asarray(yTrue)\n",
    "        acc = Evaluation(yPredicted, yTrue)\n",
    "        modelname = logPath +\"/intermediateModel.pth\"\n",
    "        torch.save(model.state_dict(), modelname)\n",
    "        print(\"Test Macro Precision\",acc[\"macroPrec\"])\n",
    "        writer.add_scalar('Test Macro Precision', acc[\"macroPrec\"], epoch)\n",
    "        writer.add_scalar('Test Micro Precision', acc[\"microPrec\"], epoch)\n",
    "        writer.add_scalar('Test Weight Precision', acc[\"weightPrec\"], epoch)\n",
    "\n",
    "        print(\"Test Macro Recall\",acc[\"macroPrec\"])\n",
    "        writer.add_scalar('Test Macro Recall', acc[\"macroRec\"], epoch)\n",
    "        writer.add_scalar('Test Micro Recall', acc[\"microRec\"], epoch)\n",
    "        writer.add_scalar('Test Weight Recall', acc[\"weightRec\"], epoch)\n",
    "\n",
    "        print(\"Test Macro F1\",acc[\"macroF1\"])\n",
    "        writer.add_scalar('Test Macro F1', acc[\"macroF1\"], epoch)\n",
    "        if acc[\"macroF1\"]>bestMacroF1:\n",
    "          bestMacroF1 = acc[\"macroF1\"]\n",
    "          modelname = logPath +\"/bestMacroF1Model.pth\"\n",
    "          torch.save(model.state_dict(), modelname)\n",
    "        writer.add_scalar('Test Micro F1', acc[\"microF1\"], epoch)\n",
    "        if acc[\"microF1\"]>bestMicroF1:\n",
    "          bestMicroF1 = acc[\"microF1\"]\n",
    "          modelname = logPath +\"/bestMicroF1Model.pth\"\n",
    "          torch.save(model.state_dict(), modelname)\n",
    "        writer.add_scalar('Test Weight F1', acc[\"weightF1\"], epoch)\n",
    "        if acc[\"weightF1\"]>bestWeightF1:\n",
    "          bestWeightF1 = acc[\"microF1\"]\n",
    "          modelname = logPath +\"/bestWeightF1Model.pth\"\n",
    "          torch.save(model.state_dict(), modelname)\n",
    "\n",
    "        writer.add_scalar('Test Macro IoU', acc[\"IoU\"], epoch)\n",
    "        print(\"Test Macro IoU\",acc[\"IoU\"])\n",
    "    if schedulerLR==\"rop\":\n",
    "        scheduler.step(sum(testLossF) / testBatches)\n",
    "    else:\n",
    "        scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./final_logs/finalModel.pth\n",
      "Best Macro F1 0.744570676303196\n",
      "Best Micro F1 0.9632898799635855\n",
      "Best Weight F1 0.9632898799635855\n",
      "Training completed\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "modelname = logPath +\"/finalModel.pth\"\n",
    "torch.save(model.state_dict(), modelname)\n",
    "print(\"Model saved to\",modelname)\n",
    "print(\"Best Macro F1\",bestMacroF1)\n",
    "print(\"Best Micro F1\",bestMicroF1)\n",
    "print(\"Best Weight F1\",bestWeightF1)\n",
    "writer.close()\n",
    "print(\"Training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Macro Precision 0.6949188971018664\n",
      "Test Micro Precision 0.9422530056029507\n",
      "Test Weight Precision 0.9621076301213273\n",
      "Test Macro Recall 0.6949188971018664\n",
      "Test Micro Recall 0.9422530056029507\n",
      "Test Weight Recall 0.9422530056029507\n",
      "Test Macro F1 0.6035286959097991\n",
      "Test Micro F1 0.9422530056029507\n",
      "Test Weight F1 0.9472755078370063\n",
      "Test Macro IoU 0.5122648042228034\n",
      "Test Subset Accuracy 0.9422530056029507\n"
     ]
    }
   ],
   "source": [
    "# loading the model\n",
    "model = ResidualAttentionUNet(11, 11)\n",
    "model.load_state_dict(torch.load(modelname))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# testing the model\n",
    "model.eval()\n",
    "testBatches = 0\n",
    "yTrue = []\n",
    "yPredicted = []\n",
    "testLossF = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (image, target) in testLoader:\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "        logits = model(image)\n",
    "        loss = criterion(logits, target)\n",
    "        logits = torch.movedim(logits, (0,1,2,3), (0,3,1,2))\n",
    "        logits = logits.reshape((-1,11))\n",
    "        target = target.reshape(-1)\n",
    "        mask = target != -1\n",
    "        logits = logits[mask]\n",
    "        target = target[mask]\n",
    "        probs = torch.nn.functional.softmax(logits, dim=1).cpu().numpy()\n",
    "        target = target.cpu().numpy()\n",
    "        testBatches += target.shape[0]\n",
    "        testLossF.append((loss.data*target.shape[0]).tolist())\n",
    "        yPredicted += probs.argmax(1).tolist()\n",
    "        yTrue += target.tolist()\n",
    "    yPredicted = np.asarray(yPredicted)\n",
    "    yTrue = np.asarray(yTrue)\n",
    "    acc = Evaluation(yPredicted, yTrue)\n",
    "    print(\"Test Macro Precision\",acc[\"macroPrec\"])\n",
    "    print(\"Test Micro Precision\",acc[\"microPrec\"])\n",
    "    print(\"Test Weight Precision\",acc[\"weightPrec\"])\n",
    "    print(\"Test Macro Recall\",acc[\"macroPrec\"])\n",
    "    print(\"Test Micro Recall\",acc[\"microRec\"])\n",
    "    print(\"Test Weight Recall\",acc[\"weightRec\"])\n",
    "    print(\"Test Macro F1\",acc[\"macroF1\"])\n",
    "    print(\"Test Micro F1\",acc[\"microF1\"])\n",
    "    print(\"Test Weight F1\",acc[\"weightF1\"])\n",
    "    print(\"Test Macro IoU\",acc[\"IoU\"])\n",
    "    print(\"Test Subset Accuracy\",acc[\"subsetAcc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0     1       2     3       4        5        6         7  \\\n",
      "0           546.0   0.0     7.0   2.0    83.0      0.0    430.0       0.0   \n",
      "1             0.0  34.0  1133.0   0.0     0.0      0.0      0.0       0.0   \n",
      "2             9.0   0.0   224.0   1.0     0.0      0.0    151.0       0.0   \n",
      "3            55.0   0.0     2.0  16.0     0.0      0.0     17.0       0.0   \n",
      "4            39.0   0.0     0.0  21.0  1114.0     36.0     62.0       0.0   \n",
      "5             0.0   0.0     0.0   0.0    88.0  15898.0   2889.0       0.0   \n",
      "6            33.0   0.0     1.0   0.0   131.0    143.0  22486.0       0.0   \n",
      "7           879.0   0.0     0.0   0.0     0.0      0.0      1.0  124673.0   \n",
      "8             3.0   0.0     0.0   0.0     3.0      0.0      1.0       7.0   \n",
      "9             0.0   0.0     0.0   0.0     0.0      4.0    824.0       0.0   \n",
      "10            0.0   0.0     0.0   0.0     0.0      0.0      4.0       0.0   \n",
      "Sum        1564.0  34.0  1367.0  40.0  1419.0  16081.0  26865.0  124680.0   \n",
      "IoU          0.26  0.03    0.15  0.14    0.68     0.82     0.78      0.99   \n",
      "Precision    0.35   1.0    0.16   0.4    0.79     0.99     0.84       1.0   \n",
      "F1-score     0.41  0.06    0.26  0.24    0.81      0.9     0.88       1.0   \n",
      "\n",
      "               8        9      10        Sum Recall  \n",
      "0            0.0      7.0     0.0     1075.0   0.51  \n",
      "1            0.0      0.0     0.0     1167.0   0.03  \n",
      "2            0.0      0.0     0.0      385.0   0.58  \n",
      "3            0.0      2.0     0.0       92.0   0.17  \n",
      "4            0.0     61.0     7.0     1340.0   0.83  \n",
      "5            0.0    149.0   238.0    19262.0   0.83  \n",
      "6            0.0   1140.0   336.0    24270.0   0.93  \n",
      "7            7.0      5.0     0.0   125565.0   0.99  \n",
      "8          279.0     76.0     0.0      369.0   0.76  \n",
      "9            0.0  34677.0  3061.0    38566.0    0.9  \n",
      "10           0.0    158.0   849.0     1011.0   0.84  \n",
      "Sum        286.0  36275.0  4491.0       mPA:   0.67  \n",
      "IoU         0.74     0.86    0.18      mIoU:   0.51  \n",
      "Precision   0.98     0.96    0.19        OA:   0.94  \n",
      "F1-score    0.85     0.93    0.31  F1-macro:    0.6  \n"
     ]
    }
   ],
   "source": [
    "unique_classes = np.unique(np.concatenate((yTrue, yPredicted)))\n",
    "labels = [str(c) for c in unique_classes]\n",
    "\n",
    "# confusion matrix\n",
    "conf_matrix = confusion_matrix(yTrue, yPredicted, labels)\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
